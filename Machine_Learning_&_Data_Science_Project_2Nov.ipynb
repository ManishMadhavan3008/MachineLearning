{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMX3BwlXWTUNnNqeV/oGdqf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManishMadhavan3008/MachineLearning/blob/main/Machine_Learning_%26_Data_Science_Project_2Nov.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.programing language : Python\n",
        "\n",
        "2.data visualization: Matplotlib\n",
        "\n",
        "3.Model building: Sklearn\n",
        "\n",
        "4.Data Cleaning :pandas\n",
        "\n",
        "5.backened server : Flask\n",
        "\n",
        "link : https://github.com/codebasics/py/blob/master/DataScience/BangloreHomePrices/model/banglore_home_prices_final.ipynb\n",
        "\n"
      ],
      "metadata": {
        "id": "cabT9gj64OL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "csv_url = \"https://raw.githubusercontent.com/codebasics/py/master/DataScience/BangloreHomePrices/model/bengaluru_house_prices.csv\"\n",
        "df1 = pd.read_csv(csv_url)\n",
        "print(df1.head())\n",
        "print(df1.shape)"
      ],
      "metadata": {
        "id": "TaiYamud4S5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#group dataanalysis\n",
        "df1.groupby('area_type')['area_type'].agg('count')"
      ],
      "metadata": {
        "id": "CKriv1vf4V31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#eleimanting columns\n",
        "df2 = df1.drop(['area_type','availability','society','balcony'],axis='columns')\n",
        "df2.head()"
      ],
      "metadata": {
        "id": "AUAAer2Q4Y2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#elemenating null\n",
        "print(df2.isnull().sum())\n",
        "df3 = df2.dropna()\n",
        "print(\"\\ndroping all NAn Values\\n\" + str(df3.isnull().sum()))"
      ],
      "metadata": {
        "id": "8Iukcr-24agS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how to see unique data fields in dataframe :\n",
        "df3['size'].unique()"
      ],
      "metadata": {
        "id": "uGR7RwZW4b7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# will show unique data but there meaning might the same to need some cleaning of data\n",
        "as we can see below\n",
        "\n",
        " array(['2 BHK', '4 Bedroom', '3 BHK', '4 BHK', '6 Bedroom', '3 Bedroom',\n",
        "       '1 BHK', '1 RK', '1 Bedroom', '8 Bedroom', '2 Bedroom',\n",
        "       '7 Bedroom', '5 BHK', '7 BHK', '6 BHK', '5 Bedroom', '11 BHK',\n",
        "       '9 BHK', '9 Bedroom', '27 BHK', '10 Bedroom', '11 Bedroom',\n",
        "       '10 BHK', '19 BHK', '16 BHK', '43 Bedroom', '14 BHK', '8 BHK',\n",
        "       '12 Bedroom', '13 BHK', '18 Bedroom'], dtype=object)\n",
        "\n",
        "\n",
        "       4 bedrrom or 4 BHK means the same so we can clean the data using token method to eliminate multi words\n",
        "\n",
        "       e.g 1 bhk , 2 bhk ... etc"
      ],
      "metadata": {
        "id": "MD6Mic9o4gdP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGFpYcj62Axy"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# creating new colum and add cleaned data by tokenization of 1 space \"words\"\n",
        "\n",
        "df3['BHK'] = df3['size'].apply(lambda x: int(x.split(' ')[0])) # we need to convert each cell as per there data Lambda function can do that\n",
        "df3.head()\n",
        "# detect any abnormal data need to clean\n",
        "df3[df3.BHK >=10]# if any thing 10 BHK room\n",
        "\n",
        "print(df3['BHK'].unique())\n",
        "print(df3['total_sqft'].unique())\n",
        "print(df3['bath'].unique())\n",
        "\n",
        "# identifying issue like this '1133 - 1384'\n",
        "def is_float(x):\n",
        "  try:\n",
        "    float(x)\n",
        "  except:\n",
        "    return False\n",
        "  return True\n",
        "\n",
        "\n",
        "\n",
        "  print(df3[df3['total_sqft'].apply(is_float)].head(25))\n",
        "  print(\"----------------------un organized data below\")\n",
        "  print(df3[~df3['total_sqft'].apply(is_float)].head(25))\n",
        "  print(df3[~df3['total_sqft'].apply(is_float)].count())\n",
        "  print(df3['total_sqft'].head(25))\n",
        "  print(df3.loc[30]) #gives u data at location 30\n",
        "# solving issue like this '1133 - 1384'\n",
        "#for that we need to replace this data to mean or average value in all columns data\n",
        "# for that we can use dedicated function or lambda function or regex.\n",
        "\n",
        "\n",
        "import re\n",
        "# Function to separate the numbers\n",
        "# and alphabets from the given string\n",
        "\n",
        "def convert_sqfeet_to_num(strin):\n",
        "    numbers0 = re.findall(r'[0-9]+', strin)\n",
        "    numbers1 = re.findall(r\"\\d+\\.\\d+\\s\", strin)\n",
        "    numbers2 = re.findall(r\"\\d+\\s+-\\s+\\d+\" +\"|\"+\"\\d+-\\s+\\d+\"+\"|\"+\"\\d+\\s+-\\d+\"+\"|\"+\"\\d+-\\d+\", strin)\n",
        "    #numbers2 = re.findall(r\"\\d+\\s+-\\s+\\d+ | \\d+-\\s+\\d+ | \\d+\\s+-\\d+ | \\d+-\\d+ | \\d*-\", str)\n",
        "    alphabets = re.findall(r'[a-zA-Z]+', strin)\n",
        "    Numlen  = len(numbers2)\n",
        "\n",
        "    # print(f\"{numbers0} and length is  {len(numbers0)}\")\n",
        "    # print(f\"{numbers1} and length is  {len(numbers1)}\")\n",
        "    # print(f\"{numbers2} and length is  {len(numbers2)}\")\n",
        "    # print(*alphabets)\n",
        "\n",
        "\n",
        "    if Numlen >= 1:\n",
        "      #return mean value\n",
        "      token = numbers2[0].split('-')\n",
        "      mean = (int(token[0]) + int(token[1]) ) /2\n",
        "      print(float(mean))\n",
        "      val = (float(mean))\n",
        "    else:\n",
        "      if(len(numbers1) >=1):\n",
        "        val = (float(numbers1[0]))\n",
        "      else:\n",
        "        if len(numbers0) >=1:\n",
        "          val= float(numbers0[0])\n",
        "        else:\n",
        "          val =  0.0\n",
        "\n",
        "    #print(f\"val is {val}\")\n",
        "    return val\n",
        "\n",
        "\n",
        "# Driver code\n",
        "#str = \"45.64 and meter\"\n",
        "# str = \"1133 -1384 and meter\"\n",
        "#str = \"1133\"\n",
        "#str = \"45.64 and meter 1133 - 1384\"\n",
        "#str = \"45.64 and 3456 meter 1133- 1384 and 1133 -1384 and 1133-1384 and 1133- orrr -6237\"\n",
        "#val = convert_sqfeet_to_num(str)\n",
        "DataVal  = ['4125Perch','1133','45.64 and meter','1133 - 1384','1133- 8765', '1133-1384', '5466334-8236']\n",
        "for Each in DataVal:\n",
        "  print(Each)\n",
        "  convert_sqfeet_to_num(Each)\n",
        "\n",
        "df4 = df3.copy()\n",
        "df4['total_sqft'] = df4['total_sqft'].apply(convert_sqfeet_to_num)\n",
        "#after cleaning let see the data\n",
        "\n",
        "print(df4.loc[30])\n",
        "print(df4.head(10))\n",
        "# outlier cleaning from data\n",
        "df5 = df4.copy()\n",
        "df5['price_per_sqfeet'] = df5['price']*100000 /df5['total_sqft']\n",
        "df5.head()"
      ]
    }
  ]
}